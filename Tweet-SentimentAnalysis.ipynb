{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Script - Sentiment Analyzer\n",
    "\n",
    "* Script used to process tweets and calculate project specific variables.\n",
    "    * Project specific variables are currently commented out\n",
    "    * Sentiment analysis and recoding is currently included\n",
    "\n",
    "**Step By Step Instructions**\n",
    "1. Adjust path to incorporate folder containing tweets you'd like to process\n",
    "2. Run script - outputted file will be called \"ProcessedTweets.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = r'./SavedTweets/'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_all_files = (pd.read_csv(f) for f in all_files)\n",
    "df = pd.concat(df_all_files, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning hashtags\n",
    "regex = \"(\\[\\d+\\, \\d+)|text|indices|\\'|\\]|\\[|\\:|}|text|\\,|{\"\n",
    "df['Hashtags'] = df.Hashtags.str.replace(regex, '').str.replace('    ', ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding date/time\n",
    "df['date'] = pd.to_datetime(df.date, infer_datetime_format=True)\n",
    "df['r_date'] = df.date.dt.date\n",
    "df['weekday'] = df.date.dt.weekday_name\n",
    "df['hour'] = df.date.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# coding week of class\\ndf.loc[((df['date'] > '2018-8-28') & (df['date'] < '2018-9-4')), 'week'] = 'Week 1'\\ndf.loc[((df['date'] > '2018-9-4') & (df['date'] < '2018-9-11')), 'week'] = 'Week 2'\\ndf.loc[((df['date'] > '2018-9-11') & (df['date'] < '2018-9-18')),'week'] = 'Week 3'\\ndf.loc[((df['date'] > '2018-9-18') & (df['date'] < '2018-9-25')), 'week'] = 'Week 4'\\ndf.loc[((df['date'] > '2018-9-25') & (df['date'] < '2018-10-2')), 'week'] = 'Week 5'\\ndf.loc[((df['date'] > '2018-10-2') & (df['date'] < '2018-10-9')), 'week'] = 'Week 6'\\ndf.loc[((df['date'] > '2018-10-9') & (df['date'] < '2018-10-16')),'week'] = 'Week 7'\\ndf.loc[((df['date'] > '2018-10-16') & (df['date'] < '2018-10-23')), 'week'] = 'Week 8'\\ndf.loc[((df['date'] > '2018-10-23') & (df['date'] < '2018-10-30')), 'week'] = 'Week 9'\\ndf.loc[((df['date'] > '2018-10-30') & (df['date'] < '2018-11-6')), 'week'] = 'Week 10'\\ndf.loc[((df['date'] > '2018-11-6') & (df['date'] < '2018-11-13')), 'week'] = 'Week 11'\\ndf.loc[((df['date'] > '2018-11-13') & (df['date'] < '2018-11-20')), 'week'] = 'Week 12'\\ndf.loc[((df['date'] > '2018-11-20') & (df['date'] < '2018-11-27')), 'week'] = 'Week 13'\\ndf.loc[((df['date'] > '2018-11-27') & (df['date'] < '2018-12-4')), 'week'] = 'Week 14'\\ndf.loc[((df['date'] > '2018-12-4') & (df['date'] < '2018-12-13')), 'week'] = 'Week 15'\\ndf.loc[((df['date'] > '2018-12-13') & (df['date'] < '2018-12-20')), 'week'] = 'Week 16'\\n\\n# week - subject\\nsubject_val = {'Week 1':'Introduction-SocialMedia+Journalism','Week 2':'Social Media Best Practices/Electronic Communication Theories/Social Media Ethics','Week 3':'SEO/Analytics and Hashtags','Week 4':'Light Side/DarkSide','Week 5':'Fake News/Business Advertising','Week 6':'Prepare Case Studies','Week 7':'GuestLecture/Case Study Homework','Week 8':'Case Study Presentation/Rise of Influencers','Week 9':'Nonprofits/Social Movements','Week 10':'Social Media and Politics','Week 11':'Multimedia Storytelling','Week 12':'Personal Privacy on Social Media','Week 13':'Thanksgiving Break','Week 14':'Careers in Social Media','Week 15':'Social Media Campaign Presentatation','Week 16':'Final Exam'}\\ndf['subject'] = df.week\\ndf.subject.replace(subject_val, inplace=True)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# coding week of class\n",
    "df.loc[((df['date'] > '2018-8-28') & (df['date'] < '2018-9-4')), 'week'] = 'Week 1'\n",
    "df.loc[((df['date'] > '2018-9-4') & (df['date'] < '2018-9-11')), 'week'] = 'Week 2'\n",
    "df.loc[((df['date'] > '2018-9-11') & (df['date'] < '2018-9-18')),'week'] = 'Week 3'\n",
    "df.loc[((df['date'] > '2018-9-18') & (df['date'] < '2018-9-25')), 'week'] = 'Week 4'\n",
    "df.loc[((df['date'] > '2018-9-25') & (df['date'] < '2018-10-2')), 'week'] = 'Week 5'\n",
    "df.loc[((df['date'] > '2018-10-2') & (df['date'] < '2018-10-9')), 'week'] = 'Week 6'\n",
    "df.loc[((df['date'] > '2018-10-9') & (df['date'] < '2018-10-16')),'week'] = 'Week 7'\n",
    "df.loc[((df['date'] > '2018-10-16') & (df['date'] < '2018-10-23')), 'week'] = 'Week 8'\n",
    "df.loc[((df['date'] > '2018-10-23') & (df['date'] < '2018-10-30')), 'week'] = 'Week 9'\n",
    "df.loc[((df['date'] > '2018-10-30') & (df['date'] < '2018-11-6')), 'week'] = 'Week 10'\n",
    "df.loc[((df['date'] > '2018-11-6') & (df['date'] < '2018-11-13')), 'week'] = 'Week 11'\n",
    "df.loc[((df['date'] > '2018-11-13') & (df['date'] < '2018-11-20')), 'week'] = 'Week 12'\n",
    "df.loc[((df['date'] > '2018-11-20') & (df['date'] < '2018-11-27')), 'week'] = 'Week 13'\n",
    "df.loc[((df['date'] > '2018-11-27') & (df['date'] < '2018-12-4')), 'week'] = 'Week 14'\n",
    "df.loc[((df['date'] > '2018-12-4') & (df['date'] < '2018-12-13')), 'week'] = 'Week 15'\n",
    "df.loc[((df['date'] > '2018-12-13') & (df['date'] < '2018-12-20')), 'week'] = 'Week 16'\n",
    "\n",
    "# week - subject\n",
    "subject_val = {'Week 1':'Introduction-SocialMedia+Journalism','Week 2':'Social Media Best Practices/Electronic Communication Theories/Social Media Ethics','Week 3':'SEO/Analytics and Hashtags','Week 4':'Light Side/DarkSide','Week 5':'Fake News/Business Advertising','Week 6':'Prepare Case Studies','Week 7':'GuestLecture/Case Study Homework','Week 8':'Case Study Presentation/Rise of Influencers','Week 9':'Nonprofits/Social Movements','Week 10':'Social Media and Politics','Week 11':'Multimedia Storytelling','Week 12':'Personal Privacy on Social Media','Week 13':'Thanksgiving Break','Week 14':'Careers in Social Media','Week 15':'Social Media Campaign Presentatation','Week 16':'Final Exam'}\n",
    "df['subject'] = df.week\n",
    "df.subject.replace(subject_val, inplace=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vader Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "data_OE = df.loc[:, ['user', 'text']]\n",
    "data_OE.fillna('0', inplace=True)\n",
    "\n",
    "columns = []\n",
    "for i in data_OE.columns:\n",
    "    if i != 'user':\n",
    "        columns.append(i+'_cmp')\n",
    "        columns.append('pos_%s'%i)\n",
    "        columns.append('neg_%s'%i)\n",
    "        columns.append('neu_%s'%i)\n",
    "\n",
    "i = 0\n",
    "df_dict = {}\n",
    "for i in np.arange(len(columns)):\n",
    "    for j in columns:\n",
    "        df_dict[j]=[]\n",
    "\n",
    "df_empty = pd.DataFrame(df_dict)\n",
    "df_empty = df_empty[columns]\n",
    "\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "\n",
    "\n",
    "i = 0;\n",
    "for i in range(0,len(list(data_OE))-1):\n",
    "    for text in data_OE.iloc[:,i+1]:\n",
    "\n",
    "        # Run Vader Analysis on each tweet\n",
    "        compound = analyzer.polarity_scores(text)[\"compound\"]\n",
    "        pos = analyzer.polarity_scores(text)[\"pos\"]\n",
    "        neu = analyzer.polarity_scores(text)[\"neu\"]\n",
    "        neg = analyzer.polarity_scores(text)[\"neg\"]\n",
    "\n",
    "        # Add each value to the appropriate array\n",
    "        compound_list.append(compound)\n",
    "        positive_list.append(pos)\n",
    "        negative_list.append(neg)\n",
    "        neutral_list.append(neu)\n",
    "\n",
    "    # print(compound_list)\n",
    "    j = (i*4);\n",
    "    k = (i*4)+1;\n",
    "    l = (i*4)+2;\n",
    "    m = (i*4)+3;\n",
    "    df_empty.iloc[:,j] = compound_list\n",
    "    df_empty.iloc[:,k] = positive_list\n",
    "    df_empty.iloc[:,l] = negative_list\n",
    "    df_empty.iloc[:,m] = neutral_list\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "\n",
    "\n",
    "# merges sentiment results into dataframe\n",
    "df = pd.merge(df,df_empty, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regrouping Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_group = df.groupby('user')\n",
    "df['Sentiment_Mean'] = user_group.text_cmp.transform('mean')\n",
    "\n",
    "'''week_group = df.groupby(['user', 'week'])\n",
    "df['Week_sent_Mean'] = week_group.text_cmp.transform('mean')\n",
    "\n",
    "# tweet counting\n",
    "df['Tweet_Number'] = df.groupby(['user']).cumcount()\n",
    "df['Tweet_Total'] = df.groupby('user').week.transform('count')\n",
    "\n",
    "df.loc[(df.Tweet_Total > 18), 'Post_Frequency'] = 'Frequent'\n",
    "df.loc[(df.Tweet_Total >= 14) & (df.Tweet_Total <= 18), 'Post_Frequency'] = 'Normal'\n",
    "df.loc[(df.Tweet_Total <= 13) & (df.Tweet_Total >= 6), 'Post_Frequency'] = 'Infrequent'\n",
    "df.loc[(df.Tweet_Total < 6), 'Post_Frequency'] = 'Very Infrequent'\n",
    "'''\n",
    "\n",
    "# Tweet Sentiment\n",
    "df.loc[(df.text_cmp >= .05), 'Tweet_Bucket'] = 'Positive'\n",
    "df.loc[(df.text_cmp < .05) & (df.text_cmp > -.05), 'Tweet_Bucket'] = 'Neutral'\n",
    "df.loc[(df.text_cmp <= -.05), 'Tweet_Bucket'] = 'Negative'\n",
    "\n",
    "\n",
    "'''subject_val = {'Week 1':1,'Week 2':2,'Week 3':3,'Week 4':4,\n",
    "               'Week 5':5,'Week 6':6,'Week 7':7,'Week 8':8,\n",
    "               'Week 9':9,'Week 10':10,'Week 11':11, 'Week 12':12,\n",
    "               'Week 13':13,'Week 14':14,'Week 15':15,'Week 16':16}\n",
    "\n",
    "df['week_num'] = df.week\n",
    "df['week_num'].replace(subject_val, inplace=True)\n",
    "'''\n",
    "\n",
    "# User Sentiment\n",
    "df.loc[(df.Sentiment_Mean >= .05), 'UserSent_Bucket'] = 'Positive'\n",
    "df.loc[(df.Sentiment_Mean < .05) & (df.Sentiment_Mean > -.05), 'UserSent_Bucket'] = 'Neutral'\n",
    "df.loc[(df.Sentiment_Mean <= -.05), 'UserSent_Bucket'] = 'Negative'\n",
    "df.UserSent_Bucket.fillna(value='Neutral', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ProcessedTweets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
