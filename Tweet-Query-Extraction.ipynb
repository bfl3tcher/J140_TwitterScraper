{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup --\n",
    "1. Ensure proper twitter credentials are saved in \"Twitter_Credentials.py\", and that the appropriate versions of the following libraries are used - \n",
    "    - json - 2.0.9\n",
    "    - pandas - .23.1\n",
    "    - numpy - 1.14.5\n",
    "    - Twython - 3.7.0\n",
    "2. Enter desired path under variable \"path\". In this instance, I have files saved to a sub-folder called \"SavedTweets\". You may need to change this so the script outputs the variable in the desired location.\n",
    "3. Enter required variable information - \n",
    "    * htag - the hashtag you're going to search for.\n",
    "    * pull_start - start date of the query\n",
    "    * pull_end - end date of the query, will only process tweets made UP TO this date.\n",
    "4. Execute script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "path = './SavedTweets/'\n",
    "\n",
    "# hashtag\n",
    "htag = '#'\n",
    "\n",
    "# extraction - start/end dates\n",
    "pull_start = '2018-12-25'\n",
    "pull_end = '2018-12-31'\n",
    "\n",
    "# export filename\n",
    "export_fn = path+htag+pull_start+'_Extracted.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hashtag Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query \n",
    "query = {\n",
    "    'q': [htag],\n",
    "    'count':100,\n",
    "    'lang': 'en',\n",
    "    'result_type':'mixed',\n",
    "    'tweet_mode':'extended',\n",
    "    'since':pull_start,\n",
    "    'until':pull_end}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Extraction Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import Twitter_Credentials\n",
    "from twython import Twython\n",
    "import json as js\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# import Twitter credentials\n",
    "tweets = Twython(\n",
    "Twitter_Credentials.CONSUMER_KEY,\n",
    "Twitter_Credentials.CONSUMER_SECRET)\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'user': [],'date': [],'text': [],'favorite_count': [],'Hashtags': []}\n",
    "\n",
    "#  Tweet query - data structure\n",
    "for status in tweets.search(**query)['statuses']:\n",
    "    dict_['user'].append(status['user']['screen_name'])\n",
    "    dict_['date'].append(status['created_at'])\n",
    "    dict_['text'].append(status['full_text'])\n",
    "    dict_['Hashtags'].append(status['entities']['hashtags'])\n",
    "\n",
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "df_day = pd.DataFrame(data=dict_,columns=['user', 'date', 'text', 'Hashtags'])\n",
    "\n",
    "# converting to date time\n",
    "df_day['date'] = pd.to_datetime(df_day.date)\n",
    "\n",
    "# export\n",
    "df_day.to_csv(export_fn, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
